{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imad267/Thesis-Work/blob/main/Gender_and_Age_Classification_Final_txt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "c70cded8-9b9e-41f6-9e2b-7b2db0eba190",
          "showTitle": false,
          "title": ""
        },
        "id": "xQPSpn2-4mio"
      },
      "source": [
        "###Load Data and Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "cb83e830-be32-4b29-b441-6d9c45144a8d",
          "showTitle": false,
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rvui3lGzlf3k",
        "outputId": "35696da8-8a17-407f-9495-add117fd409a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-10 20:06:48--  https://storage.googleapis.com/kaggle-data-sets/5958/8831/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20230410%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20230410T193922Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=60ee98d619ef8266a41c18cbb26a6a929c8cd07294f1473667789988edec800426c1bb309609e735d82feaa387de029f44569cf3d5b4ae962618182f7cb4a58716fcafebc2ca839d676b101e5bd6099d00a944d9f8f13b5c5302b200e8a7c1c65a805777dec3990c8fc0348c03979af73d3d4675c94275949932ee5a28b6362413fb43c3d352651f37a35c13444bec693e122743afce46fdf2268d0f0a3933e7609aa3e78e09a676972ed30249f72baab71511be9b81111c215df07446e5113dfa0c669fa8fc032f07e308470ea3452c7a5566d6b50cf802677a4c37edd4eaced6ddf13cb4feefcab3434000105f813f72a1e58bc9f2b319028d87fe93c75509\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.2.128, 142.250.141.128, 2607:f8b0:4023:c0b::80, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.2.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1487480072 (1.4G) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>]   1.38G   121MB/s    in 11s     \n",
            "\n",
            "2023-04-10 20:07:00 (126 MB/s) - ‘data.zip’ saved [1487480072/1487480072]\n",
            "\n",
            "/content/AdienceBenchmarkGenderAndAgeClassification\n"
          ]
        }
      ],
      "source": [
        "# Download Data from Kaggle\n",
        "!wget 'https://storage.googleapis.com/kaggle-data-sets/5958/8831/bundle/'\\\n",
        "  'archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-'\\\n",
        "  'kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20230410%2Fauto%'\\\n",
        "  '2Fstorage%2Fgoog4_request&X-Goog-Date=20230410T193922Z&X-Goog-Expires='\\\n",
        "  '259200&X-Goog-SignedHeaders=host&X-Goog-Signature=60ee98d619ef8266a41c1'\\\n",
        "  '8cbb26a6a929c8cd07294f1473667789988edec800426c1bb309609e735d82feaa387de0'\\\n",
        "  '29f44569cf3d5b4ae962618182f7cb4a58716fcafebc2ca839d676b101e5bd6099d00a9'\\\n",
        "  '44d9f8f13b5c5302b200e8a7c1c65a805777dec3990c8fc0348c03979af73d3d4675c94'\\\n",
        "  '275949932ee5a28b6362413fb43c3d352651f37a35c13444bec693e122743afce46fdf2'\\\n",
        "  '268d0f0a3933e7609aa3e78e09a676972ed30249f72baab71511be9b81111c215df0744'\\\n",
        "  '6e5113dfa0c669fa8fc032f07e308470ea3452c7a5566d6b50cf802677a4c37edd4eace'\\\n",
        "  'd6ddf13cb4feefcab3434000105f813f72a1e58bc9f2b319028d87fe93c75509' -O data.zip\n",
        "# Unzip it\n",
        "!unzip -q -u '/content/data.zip' -d '/content'\n",
        "# Remove the zip file\n",
        "!rm 'data.zip'\n",
        "# Change working directory\n",
        "%cd '/content/AdienceBenchmarkGenderAndAgeClassification/'\n",
        "# Remove unnecessory folders\n",
        "!rm -r 'AdienceBenchmarkGenderAndAgeClassification'\n",
        "!rm -r '__MACOSX'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "cd05e75b-0318-4bff-bbc7-a619516c23ff",
          "showTitle": false,
          "title": ""
        },
        "id": "U-TMFoL_sUYt"
      },
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "#import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers, Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "69209013-7f8a-4590-937d-54a2eee85963",
          "showTitle": false,
          "title": ""
        },
        "id": "_pLiafPV42YS"
      },
      "source": [
        "##Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "25bff8c9-2edc-4c42-99df-cccc690af348",
          "showTitle": false,
          "title": ""
        },
        "id": "OdsBvdtNyD4M"
      },
      "outputs": [],
      "source": [
        "# Read and concatenate all files containing labels and path information\n",
        "master = pd.concat([pd.read_csv(i, sep=\"\\t\") /\n",
        "                    for i in os.listdir() if i.endswith('.txt')]).copy()\n",
        "# Generate image path\n",
        "master['image_path'] = master[['user_id', 'face_id', 'original_image']].apply(lambda x: os.path.join('faces', f\"{x[0]}\", f\"coarse_tilt_aligned_face.{x[1]}.{x[2]}\"), axis=1)\n",
        "master.reset_index(drop = True, inplace = True)\n",
        "# Clean data\n",
        "master.dropna(inplace = True)\n",
        "master = master[master['age'] != 'None']\n",
        "master = master[master['gender'] != 'u']\n",
        "master.drop(columns = ['user_id', 'original_image', 'face_id', 'tilt_ang', 'fiducial_yaw_angle', 'fiducial_score'], inplace = True)\n",
        "# Encode target columns\n",
        "master['gender'] = master['gender'].apply(lambda x: {'f': 0, 'm': 1}.get(x))\n",
        "age_map = {i: str(sum(list(map(int, i[1:-1].split(', '))))//2) for i in sorted(master['age'].unique()) if i.startswith('(')}\n",
        "age_map = {'(27, 32)': '(25, 32)', '(38, 42)': '(38, 43)', '(38, 48)': '(38, 43)', '(8, 23)': '(15, 20)', '2': '(0, 2)', '3': '(0, 2)', '13': '(8, 12)',\n",
        " '22': '(15, 20)', '23': '(25, 32)', '29': '(25, 32)', '34': '(25, 32)', '35': '(25, 32)', '36': '(38, 43)', '42': '(38, 43)', '45': '(38, 43)',\n",
        " '46': '(48, 53)', '55': '(48, 53)', '57': '(60, 100)', '58': '(60, 100)'}\n",
        "master['age'] = master['age'].apply(lambda x: age_map.get(x, x))\n",
        "age_map = {'(0, 2)': 0, '(4, 6)': 0, '(8, 12)': 0, '(15, 20)': 1, '(25, 32)': 1, '(38, 43)': 2, '(48, 53)': 3, '(60, 100)': 3}\n",
        "inv_age = {0: '0-15', 1: '15-30', 2:'30-45', 3:'45+'}\n",
        "inv_gen = {0: 'female', 1: 'male'}\n",
        "master['age'] = master['age'].apply(lambda x: age_map.get(x, x))\n",
        "# Select partial data\n",
        "data = pd.DataFrame(columns = ['age', 'gender', 'image_path'])\n",
        "for i in range(4):\n",
        "  df1 = master[(master['gender'] == 0) & (master['age'] == i)][['age', 'gender', 'image_path']].iloc[:800]\n",
        "  df2 = master[(master['gender'] == 1) & (master['age'] == i)][['age', 'gender', 'image_path']].iloc[:800]\n",
        "  data = pd.concat([data, df1, df2])\n",
        "data.reset_index(drop = True, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "8dab8f02-3707-451f-93c7-a2e21a3336b1",
          "showTitle": false,
          "title": ""
        },
        "id": "q8eAtzRAp1nn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbabeaa0-e287-4b2b-90df-6de679d640d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6400/6400 [00:46<00:00, 138.70it/s]\n"
          ]
        }
      ],
      "source": [
        "# Load Images\n",
        "X = data['image_path']\n",
        "y_gender = data['gender']\n",
        "y_age = data['age']\n",
        "\n",
        "X_images = []\n",
        "for path in tqdm(X):\n",
        "    img = Image.open(path)\n",
        "    img = img.resize((224, 224))\n",
        "    img = np.array(img)\n",
        "    X_images.append(img)\n",
        "\n",
        "X_images = np.array(X_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "ece4cc27-9c63-496b-a32c-1b76e0850cfa",
          "showTitle": false,
          "title": ""
        },
        "id": "HfN8tlwl4gEr"
      },
      "source": [
        "#Gender Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "3591a8c4-ad10-4163-a2cf-27fc193d6293",
          "showTitle": false,
          "title": ""
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtrderPX4lax",
        "outputId": "b2084a7a-d573-4cc4-c500-3eaa131319a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 512)              0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               131328    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,879,170\n",
            "Trainable params: 164,482\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "35/35 [==============================] - ETA: 0s - loss: 1.3730 - accuracy: 0.6154 \n",
            "Epoch 1: val_accuracy improved from -inf to 0.74948, saving model to best_gender_model_1.h5\n",
            "35/35 [==============================] - 1419s 41s/step - loss: 1.3730 - accuracy: 0.6154 - val_loss: 0.5057 - val_accuracy: 0.7495\n",
            "Epoch 2/20\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.6410 - accuracy: 0.6953 \n",
            "Epoch 2: val_accuracy improved from 0.74948 to 0.77292, saving model to best_gender_model_1.h5\n",
            "35/35 [==============================] - 1367s 39s/step - loss: 0.6410 - accuracy: 0.6953 - val_loss: 0.4765 - val_accuracy: 0.7729\n",
            "Epoch 3/20\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.5233 - accuracy: 0.7433 \n",
            "Epoch 3: val_accuracy improved from 0.77292 to 0.78333, saving model to best_gender_model_1.h5\n",
            "35/35 [==============================] - 1353s 39s/step - loss: 0.5233 - accuracy: 0.7433 - val_loss: 0.4507 - val_accuracy: 0.7833\n",
            "Epoch 4/20\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4715 - accuracy: 0.7694 \n",
            "Epoch 4: val_accuracy improved from 0.78333 to 0.80260, saving model to best_gender_model_1.h5\n",
            "35/35 [==============================] - 1352s 39s/step - loss: 0.4715 - accuracy: 0.7694 - val_loss: 0.4245 - val_accuracy: 0.8026\n",
            "Epoch 5/20\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4397 - accuracy: 0.7964 \n",
            "Epoch 5: val_accuracy improved from 0.80260 to 0.81094, saving model to best_gender_model_1.h5\n",
            "35/35 [==============================] - 1364s 39s/step - loss: 0.4397 - accuracy: 0.7964 - val_loss: 0.3988 - val_accuracy: 0.8109\n",
            "Epoch 6/20\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.4236 - accuracy: 0.8054 \n",
            "Epoch 6: val_accuracy improved from 0.81094 to 0.81615, saving model to best_gender_model_1.h5\n",
            "35/35 [==============================] - 1356s 39s/step - loss: 0.4236 - accuracy: 0.8054 - val_loss: 0.3891 - val_accuracy: 0.8161\n",
            "Epoch 7/20\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3920 - accuracy: 0.8254 \n",
            "Epoch 7: val_accuracy improved from 0.81615 to 0.81771, saving model to best_gender_model_1.h5\n",
            "35/35 [==============================] - 1356s 39s/step - loss: 0.3920 - accuracy: 0.8254 - val_loss: 0.3866 - val_accuracy: 0.8177\n",
            "Epoch 8/20\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3647 - accuracy: 0.8364 \n",
            "Epoch 8: val_accuracy improved from 0.81771 to 0.82187, saving model to best_gender_model_1.h5\n",
            "35/35 [==============================] - 1359s 39s/step - loss: 0.3647 - accuracy: 0.8364 - val_loss: 0.3716 - val_accuracy: 0.8219\n",
            "Epoch 9/20\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3471 - accuracy: 0.8471 \n",
            "Epoch 9: val_accuracy improved from 0.82187 to 0.83073, saving model to best_gender_model_1.h5\n",
            "35/35 [==============================] - 1359s 39s/step - loss: 0.3471 - accuracy: 0.8471 - val_loss: 0.3572 - val_accuracy: 0.8307\n",
            "Epoch 10/20\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3296 - accuracy: 0.8594 \n",
            "Epoch 10: val_accuracy improved from 0.83073 to 0.84010, saving model to best_gender_model_1.h5\n",
            "35/35 [==============================] - 1361s 39s/step - loss: 0.3296 - accuracy: 0.8594 - val_loss: 0.3532 - val_accuracy: 0.8401\n",
            "Epoch 11/20\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.3068 - accuracy: 0.8696 \n",
            "Epoch 11: val_accuracy improved from 0.84010 to 0.84323, saving model to best_gender_model_1.h5\n",
            "35/35 [==============================] - 1359s 39s/step - loss: 0.3068 - accuracy: 0.8696 - val_loss: 0.3397 - val_accuracy: 0.8432\n",
            "Epoch 12/20\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2910 - accuracy: 0.8759 \n",
            "Epoch 12: val_accuracy improved from 0.84323 to 0.84844, saving model to best_gender_model_1.h5\n",
            "35/35 [==============================] - 1361s 39s/step - loss: 0.2910 - accuracy: 0.8759 - val_loss: 0.3363 - val_accuracy: 0.8484\n",
            "Epoch 13/20\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2796 - accuracy: 0.8797  \n",
            "Epoch 13: val_accuracy did not improve from 0.84844\n",
            "35/35 [==============================] - 5547s 162s/step - loss: 0.2796 - accuracy: 0.8797 - val_loss: 0.3490 - val_accuracy: 0.8427\n",
            "Epoch 14/20\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2616 - accuracy: 0.8935 \n",
            "Epoch 14: val_accuracy improved from 0.84844 to 0.85729, saving model to best_gender_model_1.h5\n",
            "35/35 [==============================] - 1340s 39s/step - loss: 0.2616 - accuracy: 0.8935 - val_loss: 0.3242 - val_accuracy: 0.8573\n",
            "Epoch 15/20\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2451 - accuracy: 0.8980 \n",
            "Epoch 15: val_accuracy did not improve from 0.85729\n",
            "35/35 [==============================] - 1334s 38s/step - loss: 0.2451 - accuracy: 0.8980 - val_loss: 0.3368 - val_accuracy: 0.8552\n",
            "Epoch 16/20\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2440 - accuracy: 0.8946 \n",
            "Epoch 16: val_accuracy did not improve from 0.85729\n",
            "35/35 [==============================] - 1334s 38s/step - loss: 0.2440 - accuracy: 0.8946 - val_loss: 0.3224 - val_accuracy: 0.8521\n",
            "Epoch 17/20\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2352 - accuracy: 0.9031 \n",
            "Epoch 17: val_accuracy did not improve from 0.85729\n",
            "35/35 [==============================] - 1354s 39s/step - loss: 0.2352 - accuracy: 0.9031 - val_loss: 0.3279 - val_accuracy: 0.8490\n",
            "Epoch 18/20\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.2060 - accuracy: 0.9143 \n",
            "Epoch 18: val_accuracy improved from 0.85729 to 0.86458, saving model to best_gender_model_1.h5\n",
            "35/35 [==============================] - 1350s 39s/step - loss: 0.2060 - accuracy: 0.9143 - val_loss: 0.3142 - val_accuracy: 0.8646\n",
            "Epoch 19/20\n",
            "35/35 [==============================] - ETA: 0s - loss: 0.1974 - accuracy: 0.9190 \n",
            "Epoch 19: val_accuracy did not improve from 0.86458\n",
            "35/35 [==============================] - 1345s 39s/step - loss: 0.1974 - accuracy: 0.9190 - val_loss: 0.3353 - val_accuracy: 0.8531\n",
            "Epoch 19: early stopping\n"
          ]
        }
      ],
      "source": [
        "# Generate Train Test Split\n",
        "X_train, X_test, y_gender_train, y_gender_test = train_test_split(np.asarray(X_images).astype('float32'), np.asarray(y_gender.values).astype('float32'), test_size=0.3, stratify = y_gender, random_state=0)\n",
        "# Set up callbacks for early stopping and generating checkpoints\n",
        "es = EarlyStopping(monitor='val_accuracy', min_delta= 0.01 , patience= 5, verbose= 1, mode='auto')\n",
        "mc = ModelCheckpoint(filepath=\"best_gender_model_1.h5\", monitor= 'val_accuracy', verbose= 1, save_best_only= True, mode = 'auto')\n",
        "call_back = [es, mc]\n",
        "# Load Pre trained model\n",
        "vgg16_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
        "# Make layers' weights static\n",
        "for layer in vgg16_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Initialize a sequential model\n",
        "model_gender = Sequential()\n",
        "model_gender.add(vgg16_model)\n",
        "model_gender.add(layers.GlobalAveragePooling2D())\n",
        "model_gender.add(layers.Flatten())\n",
        "model_gender.add(layers.Dense(256, activation=\"relu\"))\n",
        "model_gender.add(layers.Dropout(0.5))\n",
        "model_gender.add(layers.Dense(128, activation=\"relu\"))\n",
        "model_gender.add(layers.Dropout(0.5))\n",
        "model_gender.add(layers.Dense(2, activation=\"softmax\"))\n",
        "model_gender.summary()\n",
        "# Compile the model\n",
        "model_gender.compile(loss=SparseCategoricalCrossentropy(),\\\n",
        "                     optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the neural network/model\n",
        "history_gender = model_gender.fit(X_train, y_gender_train, batch_size=128,\n",
        "                                  epochs=20, validation_batch_size=128,\n",
        "                                  validation_data=(X_test, y_gender_test), \n",
        "                                  callbacks=[es, mc])\n",
        "model_gender.save('gender_model_1.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "8bb8f044-1038-4354-ab39-4e15acd1baef",
          "showTitle": false,
          "title": ""
        },
        "id": "T405xcVI4jWG"
      },
      "source": [
        "#Age Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "1161b178-d6af-43ba-8d3f-c19551630a81",
          "showTitle": false,
          "title": ""
        },
        "id": "DPFDtXXXRuXw",
        "outputId": "accefdff-8647-4afa-fb20-4de5c5577edc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 512)              0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               131328    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 4)                 516       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,879,428\n",
            "Trainable params: 164,740\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "40/40 [==============================] - ETA: 0s - loss: 2.5576 - accuracy: 0.3236"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 128 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.41719, saving model to best_age_model_1.h5\n",
            "40/40 [==============================] - 17s 145ms/step - loss: 2.5576 - accuracy: 0.3236 - val_loss: 1.2196 - val_accuracy: 0.4172\n",
            "Epoch 2/30\n",
            "40/40 [==============================] - ETA: 0s - loss: 1.3508 - accuracy: 0.3945"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r40/40 [==============================] - 3s 84ms/step - loss: 1.3508 - accuracy: 0.3945\n",
            "Epoch 3/30\n",
            "40/40 [==============================] - ETA: 0s - loss: 1.2217 - accuracy: 0.4307"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r40/40 [==============================] - 3s 83ms/step - loss: 1.2217 - accuracy: 0.4307\n",
            "Epoch 4/30\n",
            "40/40 [==============================] - ETA: 0s - loss: 1.1422 - accuracy: 0.4699"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r40/40 [==============================] - 3s 83ms/step - loss: 1.1422 - accuracy: 0.4699\n",
            "Epoch 5/30\n",
            "40/40 [==============================] - ETA: 0s - loss: 1.1012 - accuracy: 0.4824"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r40/40 [==============================] - 3s 83ms/step - loss: 1.1012 - accuracy: 0.4824\n",
            "Epoch 6/30\n",
            "40/40 [==============================] - ETA: 0s - loss: 1.0469 - accuracy: 0.5166"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r40/40 [==============================] - 3s 83ms/step - loss: 1.0469 - accuracy: 0.5166\n",
            "Epoch 7/30\n",
            "40/40 [==============================] - ETA: 0s - loss: 1.0131 - accuracy: 0.5338"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r40/40 [==============================] - 3s 84ms/step - loss: 1.0131 - accuracy: 0.5338\n",
            "Epoch 8/30\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.9884 - accuracy: 0.5516"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r40/40 [==============================] - 3s 83ms/step - loss: 0.9884 - accuracy: 0.5516\n",
            "Epoch 9/30\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.9380 - accuracy: 0.5734"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r40/40 [==============================] - 3s 84ms/step - loss: 0.9380 - accuracy: 0.5734\n",
            "Epoch 10/30\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.9405 - accuracy: 0.5813"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r40/40 [==============================] - 3s 83ms/step - loss: 0.9405 - accuracy: 0.5813\n",
            "Epoch 11/30\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.9019 - accuracy: 0.6008"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r40/40 [==============================] - 3s 84ms/step - loss: 0.9019 - accuracy: 0.6008\n",
            "Epoch 12/30\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.8690 - accuracy: 0.6197"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r40/40 [==============================] - 3s 83ms/step - loss: 0.8690 - accuracy: 0.6197\n",
            "Epoch 13/30\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.8565 - accuracy: 0.6230"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r40/40 [==============================] - 3s 84ms/step - loss: 0.8565 - accuracy: 0.6230\n",
            "Epoch 14/30\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.8313 - accuracy: 0.6371"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r40/40 [==============================] - 3s 84ms/step - loss: 0.8313 - accuracy: 0.6371\n",
            "Epoch 15/30\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.8071 - accuracy: 0.6494"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r40/40 [==============================] - 3s 84ms/step - loss: 0.8071 - accuracy: 0.6494\n",
            "Epoch 16/30\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7899 - accuracy: 0.6588"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r40/40 [==============================] - 3s 82ms/step - loss: 0.7899 - accuracy: 0.6588\n",
            "Epoch 17/30\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7704 - accuracy: 0.6678"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r40/40 [==============================] - 3s 84ms/step - loss: 0.7704 - accuracy: 0.6678\n",
            "Epoch 18/30\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7359 - accuracy: 0.6766"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r40/40 [==============================] - 3s 83ms/step - loss: 0.7359 - accuracy: 0.6766\n",
            "Epoch 19/30\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6971 - accuracy: 0.6963"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r40/40 [==============================] - 3s 83ms/step - loss: 0.6971 - accuracy: 0.6963\n",
            "Epoch 20/30\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.7106 - accuracy: 0.7027"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r40/40 [==============================] - 3s 83ms/step - loss: 0.7106 - accuracy: 0.7027\n",
            "Epoch 21/30\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6700 - accuracy: 0.7172"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r40/40 [==============================] - 3s 83ms/step - loss: 0.6700 - accuracy: 0.7172\n",
            "Epoch 22/30\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6505 - accuracy: 0.7162"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r40/40 [==============================] - 3s 84ms/step - loss: 0.6505 - accuracy: 0.7162\n",
            "Epoch 23/30\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6265 - accuracy: 0.7396"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r40/40 [==============================] - 3s 84ms/step - loss: 0.6265 - accuracy: 0.7396\n",
            "Epoch 24/30\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6260 - accuracy: 0.7402"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r40/40 [==============================] - 3s 83ms/step - loss: 0.6260 - accuracy: 0.7402\n",
            "Epoch 25/30\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.6314 - accuracy: 0.7238"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r40/40 [==============================] - 3s 83ms/step - loss: 0.6314 - accuracy: 0.7238\n",
            "Epoch 26/30\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.5943 - accuracy: 0.7529"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r40/40 [==============================] - 3s 83ms/step - loss: 0.5943 - accuracy: 0.7529\n",
            "Epoch 27/30\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.5745 - accuracy: 0.7602"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r40/40 [==============================] - 3s 83ms/step - loss: 0.5745 - accuracy: 0.7602\n",
            "Epoch 28/30\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.5547 - accuracy: 0.7660"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r40/40 [==============================] - 3s 83ms/step - loss: 0.5547 - accuracy: 0.7660\n",
            "Epoch 29/30\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.5366 - accuracy: 0.7795"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r40/40 [==============================] - 3s 83ms/step - loss: 0.5366 - accuracy: 0.7795\n",
            "Epoch 30/30\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.5153 - accuracy: 0.7840"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r40/40 [==============================] - 3s 83ms/step - loss: 0.5153 - accuracy: 0.7840\n"
          ]
        }
      ],
      "source": [
        "# Train Test Split\n",
        "X_train, X_test, y_age_train, y_age_test = train_test_split(np.asarray(X_images).astype('float32'), np.asarray(y_age.values).astype('float32'), test_size=0.2, stratify = y_age, random_state=0)\n",
        "# Generate Callbacks\n",
        "es = EarlyStopping(monitor='val_accuracy', min_delta= 0.01 , patience= 5, verbose= 1, mode='auto')\n",
        "mc = ModelCheckpoint(filepath=\"best_age_model_1.h5\", monitor= 'val_accuracy', verbose= 1, save_best_only= True, mode = 'auto')\n",
        "call_back = [es, mc]\n",
        "# Load Pretrained model\n",
        "vgg16_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "for layer in vgg16_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Initialize a sequential model\n",
        "model_age = Sequential()\n",
        "model_age.add(vgg16_model)\n",
        "model_age.add(layers.GlobalAveragePooling2D())\n",
        "model_age.add(layers.Flatten())\n",
        "model_age.add(layers.Dense(256, activation=\"relu\"))\n",
        "model_age.add(layers.Dropout(0.5))\n",
        "model_age.add(layers.Dense(128, activation=\"relu\"))\n",
        "model_age.add(layers.Dropout(0.5))\n",
        "model_age.add(layers.Dense(4, activation=\"softmax\"))\n",
        "model_age.summary()\n",
        "\n",
        "model_age.compile(loss=SparseCategoricalCrossentropy(), optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the neural network/model\n",
        "history_age = model_age.fit(X_train, y_age_train, batch_size=128, epochs=30, validation_steps= 128, validation_data=(X_test, y_age_test), callbacks=[es, mc])\n",
        "model_age.save('age_model_1.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFtYWR1zRuXz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "dashboards": [],
      "language": "python",
      "notebookMetadata": {
        "pythonIndentUnit": 2
      },
      "notebookName": "Gender_and_Age_Classification (2)",
      "notebookOrigID": 1924068764638026,
      "widgets": {}
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}